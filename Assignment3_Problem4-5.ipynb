{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd8ea1a4-9edb-41e9-b146-d3085a6f60bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ee645f2-728c-4c93-b35f-7a16a7c14b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "220445c3-66ea-4a3e-86cc-a8b9601593dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 2000 images\n",
      "Validation set: 1000 images\n",
      "Test set: 1000 images\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Function to create train, validation, and test sets\n",
    "def create_dataset_splits(source_dir, train_dir, val_dir, test_dir, num_train, num_val, num_test):\n",
    "    for dir in [train_dir, val_dir, test_dir]:\n",
    "        os.makedirs(os.path.join(dir, 'cats'), exist_ok=True)\n",
    "        os.makedirs(os.path.join(dir, 'dogs'), exist_ok=True)\n",
    "\n",
    "    for animal in ['cat', 'dog']:\n",
    "        animal_files = [f for f in os.listdir(source_dir) if f.startswith(animal)]\n",
    "        random.shuffle(animal_files)\n",
    "\n",
    "        for i, file in enumerate(animal_files):\n",
    "            if i < num_train:\n",
    "                shutil.copy(os.path.join(source_dir, file), os.path.join(train_dir, f'{animal}s', file))\n",
    "            elif i < num_train + num_val:\n",
    "                shutil.copy(os.path.join(source_dir, file), os.path.join(val_dir, f'{animal}s', file))\n",
    "            elif i < num_train + num_val + num_test:\n",
    "                shutil.copy(os.path.join(source_dir, file), os.path.join(test_dir, f'{animal}s', file))\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    print(f\"Train set: {len(os.listdir(os.path.join(train_dir, 'cats'))) + len(os.listdir(os.path.join(train_dir, 'dogs')))} images\")\n",
    "    print(f\"Validation set: {len(os.listdir(os.path.join(val_dir, 'cats'))) + len(os.listdir(os.path.join(val_dir, 'dogs')))} images\")\n",
    "    print(f\"Test set: {len(os.listdir(os.path.join(test_dir, 'cats'))) + len(os.listdir(os.path.join(test_dir, 'dogs')))} images\")\n",
    "\n",
    "\n",
    "# Create dataset splits\n",
    "source_dir = 'D:/Test/Deep_Learning/Assignment_3/dogs-vs-cats/train'\n",
    "train_dir = 'D:/Test/Deep_Learning/Assignment_3/dataset1/train'\n",
    "val_dir = 'D:/Test/Deep_Learning/Assignment_3/dataset1/validation'\n",
    "test_dir = 'D:/Test/Deep_Learning/Assignment_3/dataset1/test'\n",
    "\n",
    "create_dataset_splits(source_dir, train_dir, val_dir, test_dir, 1000, 500, 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1850fa5-4414-4c69-9b0e-d27fd80f9cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(150, 150),\n",
    "                                                    batch_size=32, class_mode='binary')\n",
    "\n",
    "validation_generator = val_test_datagen.flow_from_directory(val_dir, target_size=(150, 150),\n",
    "                                                            batch_size=32, class_mode='binary')\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(test_dir, target_size=(150, 150),\n",
    "                                                      batch_size=32, class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e817a32-f931-4913-90d3-a66dedad943b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29f54f01-a611-4497-9456-bc6156b745cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"vgg16\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"vgg16\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block1_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block1_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block1_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block2_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block2_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block2_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block3_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block3_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block3_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block3_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block4_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block4_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block4_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block4_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block5_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block5_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block5_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block5_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block1_conv1 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m1,792\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block1_conv2 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m36,928\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block1_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block2_conv1 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block2_conv2 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │         \u001b[38;5;34m147,584\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block2_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block3_conv1 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m295,168\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block3_conv2 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m590,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block3_conv3 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m590,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block3_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block4_conv1 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m1,180,160\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block4_conv2 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block4_conv3 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block4_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block5_conv1 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block5_conv2 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block5_conv3 (\u001b[38;5;33mConv2D\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ block5_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> (56.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,714,688\u001b[0m (56.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> (56.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14,714,688\u001b[0m (56.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15fc432f-2ddf-46c8-b526-71ddc777415a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 images belonging to 2 classes.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m features, labels\n\u001b[0;32m     35\u001b[0m train_features, train_labels \u001b[38;5;241m=\u001b[39m extract_features(train_dir, \u001b[38;5;241m2000\u001b[39m)\n\u001b[1;32m---> 36\u001b[0m validation_features, validation_labels \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalidation_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m test_features, test_labels \u001b[38;5;241m=\u001b[39m extract_features(test_dir, \u001b[38;5;241m1000\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 25\u001b[0m, in \u001b[0;36mextract_features\u001b[1;34m(directory, sample_count)\u001b[0m\n\u001b[0;32m     23\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs_batch, labels_batch \u001b[38;5;129;01min\u001b[39;00m generator:\n\u001b[1;32m---> 25\u001b[0m     features_batch \u001b[38;5;241m=\u001b[39m \u001b[43mconv_base\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     features[i \u001b[38;5;241m*\u001b[39m batch_size : (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m batch_size] \u001b[38;5;241m=\u001b[39m features_batch\n\u001b[0;32m     27\u001b[0m     labels[i \u001b[38;5;241m*\u001b[39m batch_size : (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m batch_size] \u001b[38;5;241m=\u001b[39m labels_batch\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\deeplearn\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\deeplearn\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:512\u001b[0m, in \u001b[0;36mTensorFlowTrainer.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[0;32m    510\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[0;32m    511\u001b[0m data \u001b[38;5;241m=\u001b[39m get_data(iterator)\n\u001b[1;32m--> 512\u001b[0m batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    513\u001b[0m outputs \u001b[38;5;241m=\u001b[39m append_to_outputs(batch_outputs, outputs)\n\u001b[0;32m    514\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_end(step, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: batch_outputs})\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\deeplearn\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\deeplearn\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\deeplearn\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\deeplearn\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\deeplearn\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\deeplearn\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\deeplearn\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\deeplearn\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1567\u001b[0m   )\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\deeplearn\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "base_dir = 'D:/Test/Deep_Learning/Assignment_3/cats_and_dogs_small1'\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 20\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
    "    labels = np.zeros(shape=(sample_count))\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            # Note that since generators yield data indefinitely in a loop,\n",
    "            # we must `break` after every image has been seen once.\n",
    "            break\n",
    "    return features, labels\n",
    "\n",
    "train_features, train_labels = extract_features(train_dir, 2000)\n",
    "validation_features, validation_labels = extract_features(validation_dir, 1000)\n",
    "test_features, test_labels = extract_features(test_dir, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d15af3dc-f673-4009-b991-82b5a80dbc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 images belonging to 2 classes.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Found 2000 images belonging to 2 classes.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Found 2000 images belonging to 2 classes.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Train features shape: (2000, 4, 4, 512)\n",
      "Train labels shape: (2000,)\n",
      "Validation features shape: (1000, 4, 4, 512)\n",
      "Validation labels shape: (1000,)\n",
      "Test features shape: (1000, 4, 4, 512)\n",
      "Test labels shape: (1000,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16  # or any other pretrained model\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define base directory for the dataset\n",
    "base_dir = 'D:/Test/Deep_Learning/Assignment_3/cats_and_dogs_small1'\n",
    "\n",
    "# Define directories for training, validation, and testing\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "# Initialize ImageDataGenerator for rescaling\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 20\n",
    "\n",
    "# Load the pretrained model (e.g., VGG16) without the top layers\n",
    "conv_base = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, 4, 4, 512))  # Adjust shape based on your model's output\n",
    "    labels = np.zeros(shape=(sample_count))\n",
    "    \n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        shuffle=False)  # Set shuffle=False to maintain order for labels\n",
    "\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        \n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "# Extract features and labels from training, validation, and test datasets\n",
    "train_features, train_labels = extract_features(train_dir, 2000)\n",
    "validation_features, validation_labels = extract_features(validation_dir, 1000)\n",
    "test_features, test_labels = extract_features(test_dir, 1000)\n",
    "\n",
    "# Print shapes of extracted features and labels for verification\n",
    "print(\"Train features shape:\", train_features.shape)\n",
    "print(\"Train labels shape:\", train_labels.shape)\n",
    "print(\"Validation features shape:\", validation_features.shape)\n",
    "print(\"Validation labels shape:\", validation_labels.shape)\n",
    "print(\"Test features shape:\", test_features.shape)\n",
    "print(\"Test labels shape:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a9b62fb-d1da-431e-bbac-94e2644c7666",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.reshape(train_features, (2000, 4 * 4 * 512))\n",
    "validation_features = np.reshape(validation_features, (1000, 4 * 4 * 512))\n",
    "test_features = np.reshape(test_features, (1000, 4 * 4 * 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ee84467-4f6b-45bf-9221-e76b131e26f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.9841 - loss: 0.0623 - val_accuracy: 1.0000 - val_loss: 2.8534e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 3.1856e-04 - val_accuracy: 1.0000 - val_loss: 4.1489e-05\n",
      "Epoch 3/30\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 1.0553e-04 - val_accuracy: 1.0000 - val_loss: 1.8596e-05\n",
      "Epoch 4/30\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 4.2832e-05 - val_accuracy: 1.0000 - val_loss: 1.1559e-05\n",
      "Epoch 5/30\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 3.2571e-05 - val_accuracy: 1.0000 - val_loss: 8.0040e-06\n",
      "Epoch 6/30\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 2.0897e-05 - val_accuracy: 1.0000 - val_loss: 6.3289e-06\n",
      "Epoch 7/30\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.6469e-05 - val_accuracy: 1.0000 - val_loss: 5.1756e-06\n",
      "Epoch 8/30\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.6472e-05 - val_accuracy: 1.0000 - val_loss: 4.2511e-06\n",
      "Epoch 9/30\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.2568e-05 - val_accuracy: 1.0000 - val_loss: 3.6195e-06\n",
      "Epoch 10/30\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.1404e-05 - val_accuracy: 1.0000 - val_loss: 3.1846e-06\n",
      "Epoch 11/30\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.2053e-05 - val_accuracy: 1.0000 - val_loss: 2.8168e-06\n",
      "Epoch 12/30\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 8.2489e-06 - val_accuracy: 1.0000 - val_loss: 2.5379e-06\n",
      "Epoch 13/30\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 8.0478e-06 - val_accuracy: 1.0000 - val_loss: 2.3224e-06\n",
      "Epoch 14/30\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 6.8610e-06 - val_accuracy: 1.0000 - val_loss: 2.1359e-06\n",
      "Epoch 15/30\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 6.2647e-06 - val_accuracy: 1.0000 - val_loss: 1.9630e-06\n",
      "Epoch 16/30\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 6.8239e-06 - val_accuracy: 1.0000 - val_loss: 1.8067e-06\n",
      "Epoch 17/30\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 6.0891e-06 - val_accuracy: 1.0000 - val_loss: 1.6787e-06\n",
      "Epoch 18/30\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 6.2213e-06 - val_accuracy: 1.0000 - val_loss: 1.5566e-06\n",
      "Epoch 19/30\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 4.9778e-06 - val_accuracy: 1.0000 - val_loss: 1.4639e-06\n",
      "Epoch 20/30\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 5.0698e-06 - val_accuracy: 1.0000 - val_loss: 1.3721e-06\n",
      "Epoch 21/30\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 5.2069e-06 - val_accuracy: 1.0000 - val_loss: 1.2838e-06\n",
      "Epoch 22/30\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 6.1375e-06 - val_accuracy: 1.0000 - val_loss: 1.2052e-06\n",
      "Epoch 23/30\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 4.6750e-06 - val_accuracy: 1.0000 - val_loss: 1.1346e-06\n",
      "Epoch 24/30\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 3.3216e-06 - val_accuracy: 1.0000 - val_loss: 1.0860e-06\n",
      "Epoch 25/30\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 4.8937e-06 - val_accuracy: 1.0000 - val_loss: 1.0301e-06\n",
      "Epoch 26/30\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 4.3449e-06 - val_accuracy: 1.0000 - val_loss: 9.7728e-07\n",
      "Epoch 27/30\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 4.6165e-06 - val_accuracy: 1.0000 - val_loss: 9.3351e-07\n",
      "Epoch 28/30\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 3.6329e-06 - val_accuracy: 1.0000 - val_loss: 8.9280e-07\n",
      "Epoch 29/30\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 3.7692e-06 - val_accuracy: 1.0000 - val_loss: 8.5135e-07\n",
      "Epoch 30/30\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 4.0407e-06 - val_accuracy: 1.0000 - val_loss: 8.1360e-07\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_dim=4 * 4 * 512))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(learning_rate=2e-5),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_features, train_labels,\n",
    "                    epochs=30,\n",
    "                    batch_size=20,\n",
    "                    validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e1ef2ac-61b5-48c2-95ad-aa467433e7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a88a39e6-e5ac-4395-8069-8ef57001021b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras import models\n",
    "# from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b99f57b5-fe58-41f9-b9e0-b733b68b5657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ vgg16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,408</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ vgg16 (\u001b[38;5;33mFunctional\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │      \u001b[38;5;34m14,714,688\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │       \u001b[38;5;34m2,097,408\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m257\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,812,353</span> (64.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,812,353\u001b[0m (64.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,812,353</span> (64.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,812,353\u001b[0m (64.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49da7598-a97d-4fff-9f77-b32a764cbb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of trainable weights before freezing the conv base: 30\n"
     ]
    }
   ],
   "source": [
    "print('This is the number of trainable weights '\n",
    "      'before freezing the conv base:', len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c56685d2-97f1-4e3e-b12b-81359d5c6256",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2bf77eb-1258-45bd-b326-bc24d744c4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of trainable weights after freezing the conv base: 4\n"
     ]
    }
   ],
   "source": [
    "print('This is the number of trainable weights '\n",
    "      'after freezing the conv base:', len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71bd7890-636c-4790-acaa-4e6b17ec9a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1041238\\Anaconda3\\envs\\deeplearn\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 - 227s - 2s/step - accuracy: 0.6850 - loss: 0.5946 - val_accuracy: 0.8320 - val_loss: 0.4441\n",
      "Epoch 2/30\n",
      "100/100 - 261s - 3s/step - accuracy: 0.7790 - loss: 0.4846 - val_accuracy: 0.8630 - val_loss: 0.3619\n",
      "Epoch 3/30\n",
      "100/100 - 0s - 1ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1041238\\Anaconda3\\envs\\deeplearn\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 35\u001b[0m\n\u001b[0;32m     25\u001b[0m validation_generator \u001b[38;5;241m=\u001b[39m test_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[0;32m     26\u001b[0m         validation_dir,\n\u001b[0;32m     27\u001b[0m         target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m150\u001b[39m, \u001b[38;5;241m150\u001b[39m),\n\u001b[0;32m     28\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m     29\u001b[0m         class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     31\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mRMSprop(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2e-5\u001b[39m),\n\u001b[0;32m     32\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     33\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 35\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m      \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m      \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m      \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\deeplearn\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\deeplearn\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    322\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\deeplearn\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\deeplearn\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\deeplearn\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\deeplearn\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\deeplearn\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\deeplearn\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\deeplearn\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\deeplearn\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1567\u001b[0m   )\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\deeplearn\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(learning_rate=2e-5),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=30,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,\n",
    "      verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67c06a0b-b2f2-4eaf-b673-f58453722322",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cats_and_dogs_small_3.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09edc2b4-19a4-47a4-bc0d-262c576ab200",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c4fb99-5b37-4d52-aea5-de3001e428cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb983cc1-1c5a-4922-b5ac-343204b24163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bf20c7-365a-4753-a6b9-dd7c2c649218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80681c1b-abbc-4ad5-9e10-538a51adce42",
   "metadata": {},
   "source": [
    "### Problem 5: Fine Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b26f407-19c8-4c42-8f86-2fdaabf621be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.applications import VGG16, Xception\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d730af2-8f7e-4ad1-a21e-f5d73fc24720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_layer_5\n",
      "1 block1_conv1\n",
      "2 block1_conv2\n",
      "3 block1_pool\n",
      "4 block2_conv1\n",
      "5 block2_conv2\n",
      "6 block2_pool\n",
      "7 block3_conv1\n",
      "8 block3_conv2\n",
      "9 block3_conv3\n",
      "10 block3_pool\n",
      "11 block4_conv1\n",
      "12 block4_conv2\n",
      "13 block4_conv3\n",
      "14 block4_pool\n",
      "15 block5_conv1\n",
      "16 block5_conv2\n",
      "17 block5_conv3\n",
      "18 block5_pool\n"
     ]
    }
   ],
   "source": [
    "# Load VGG16 model without top layers\n",
    "conv_base_vgg = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "\n",
    "# Unfreeze the last three convolutional layers\n",
    "for layer in conv_base_vgg.layers[-3:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Print layer names to verify\n",
    "for i, layer in enumerate(conv_base_vgg.layers):\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d62b4e4f-bdbb-4aca-b9cb-c39c0ba44f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m83683744/83683744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 0us/step\n",
      "0 input_layer_6\n",
      "1 block1_conv1\n",
      "2 block1_conv1_bn\n",
      "3 block1_conv1_act\n",
      "4 block1_conv2\n",
      "5 block1_conv2_bn\n",
      "6 block1_conv2_act\n",
      "7 block2_sepconv1\n",
      "8 block2_sepconv1_bn\n",
      "9 block2_sepconv2_act\n",
      "10 block2_sepconv2\n",
      "11 block2_sepconv2_bn\n",
      "12 conv2d\n",
      "13 block2_pool\n",
      "14 batch_normalization\n",
      "15 add\n",
      "16 block3_sepconv1_act\n",
      "17 block3_sepconv1\n",
      "18 block3_sepconv1_bn\n",
      "19 block3_sepconv2_act\n",
      "20 block3_sepconv2\n",
      "21 block3_sepconv2_bn\n",
      "22 conv2d_1\n",
      "23 block3_pool\n",
      "24 batch_normalization_1\n",
      "25 add_1\n",
      "26 block4_sepconv1_act\n",
      "27 block4_sepconv1\n",
      "28 block4_sepconv1_bn\n",
      "29 block4_sepconv2_act\n",
      "30 block4_sepconv2\n",
      "31 block4_sepconv2_bn\n",
      "32 conv2d_2\n",
      "33 block4_pool\n",
      "34 batch_normalization_2\n",
      "35 add_2\n",
      "36 block5_sepconv1_act\n",
      "37 block5_sepconv1\n",
      "38 block5_sepconv1_bn\n",
      "39 block5_sepconv2_act\n",
      "40 block5_sepconv2\n",
      "41 block5_sepconv2_bn\n",
      "42 block5_sepconv3_act\n",
      "43 block5_sepconv3\n",
      "44 block5_sepconv3_bn\n",
      "45 add_3\n",
      "46 block6_sepconv1_act\n",
      "47 block6_sepconv1\n",
      "48 block6_sepconv1_bn\n",
      "49 block6_sepconv2_act\n",
      "50 block6_sepconv2\n",
      "51 block6_sepconv2_bn\n",
      "52 block6_sepconv3_act\n",
      "53 block6_sepconv3\n",
      "54 block6_sepconv3_bn\n",
      "55 add_4\n",
      "56 block7_sepconv1_act\n",
      "57 block7_sepconv1\n",
      "58 block7_sepconv1_bn\n",
      "59 block7_sepconv2_act\n",
      "60 block7_sepconv2\n",
      "61 block7_sepconv2_bn\n",
      "62 block7_sepconv3_act\n",
      "63 block7_sepconv3\n",
      "64 block7_sepconv3_bn\n",
      "65 add_5\n",
      "66 block8_sepconv1_act\n",
      "67 block8_sepconv1\n",
      "68 block8_sepconv1_bn\n",
      "69 block8_sepconv2_act\n",
      "70 block8_sepconv2\n",
      "71 block8_sepconv2_bn\n",
      "72 block8_sepconv3_act\n",
      "73 block8_sepconv3\n",
      "74 block8_sepconv3_bn\n",
      "75 add_6\n",
      "76 block9_sepconv1_act\n",
      "77 block9_sepconv1\n",
      "78 block9_sepconv1_bn\n",
      "79 block9_sepconv2_act\n",
      "80 block9_sepconv2\n",
      "81 block9_sepconv2_bn\n",
      "82 block9_sepconv3_act\n",
      "83 block9_sepconv3\n",
      "84 block9_sepconv3_bn\n",
      "85 add_7\n",
      "86 block10_sepconv1_act\n",
      "87 block10_sepconv1\n",
      "88 block10_sepconv1_bn\n",
      "89 block10_sepconv2_act\n",
      "90 block10_sepconv2\n",
      "91 block10_sepconv2_bn\n",
      "92 block10_sepconv3_act\n",
      "93 block10_sepconv3\n",
      "94 block10_sepconv3_bn\n",
      "95 add_8\n",
      "96 block11_sepconv1_act\n",
      "97 block11_sepconv1\n",
      "98 block11_sepconv1_bn\n",
      "99 block11_sepconv2_act\n",
      "100 block11_sepconv2\n",
      "101 block11_sepconv2_bn\n",
      "102 block11_sepconv3_act\n",
      "103 block11_sepconv3\n",
      "104 block11_sepconv3_bn\n",
      "105 add_9\n",
      "106 block12_sepconv1_act\n",
      "107 block12_sepconv1\n",
      "108 block12_sepconv1_bn\n",
      "109 block12_sepconv2_act\n",
      "110 block12_sepconv2\n",
      "111 block12_sepconv2_bn\n",
      "112 block12_sepconv3_act\n",
      "113 block12_sepconv3\n",
      "114 block12_sepconv3_bn\n",
      "115 add_10\n",
      "116 block13_sepconv1_act\n",
      "117 block13_sepconv1\n",
      "118 block13_sepconv1_bn\n",
      "119 block13_sepconv2_act\n",
      "120 block13_sepconv2\n",
      "121 block13_sepconv2_bn\n",
      "122 conv2d_3\n",
      "123 block13_pool\n",
      "124 batch_normalization_3\n",
      "125 add_11\n",
      "126 block14_sepconv1\n",
      "127 block14_sepconv1_bn\n",
      "128 block14_sepconv1_act\n",
      "129 block14_sepconv2\n",
      "130 block14_sepconv2_bn\n",
      "131 block14_sepconv2_act\n"
     ]
    }
   ],
   "source": [
    "# Load Xception model without top layers\n",
    "conv_base_xception = Xception(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
    "\n",
    "# Unfreeze the last two separable convolutional layers and the dense classification layers\n",
    "for layer in conv_base_xception.layers[-2:]:  # Last two separable convolutional layers\n",
    "    layer.trainable = True\n",
    "\n",
    "# Also unfreeze dense classification layers if needed (adjust based on your architecture)\n",
    "for layer in conv_base_xception.layers[-5:]:  # Adjust this slice based on your needs\n",
    "    layer.trainable = True\n",
    "\n",
    "# Print layer names to verify\n",
    "for i, layer in enumerate(conv_base_xception.layers):\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "644a1a5e-99ac-4fb6-99a9-6c2182acad5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Image data generators for VGG16 (150x150) and Xception (299x299)\n",
    "# datagen_vgg = ImageDataGenerator(rescale=1./255)\n",
    "# datagen_xception = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(        \n",
    "        train_dir,        \n",
    "        target_size=(299, 299),\n",
    "        batch_size=32,        \n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(299, 299),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7401f06e-4872-4890-8387-c7c367541f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Xception\n",
    "model_xception = models.Sequential()\n",
    "model_xception.add(conv_base_xception)\n",
    "model_xception.add(layers.GlobalAveragePooling2D())\n",
    "model_xception.add(layers.Dense(256, activation='relu'))\n",
    "model_xception.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_xception.compile(optimizer=optimizers.RMSprop(learning_rate=2e-5),\n",
    "                       loss='binary_crossentropy',\n",
    "                       metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f524897d-11a6-4c28-883d-c962595e10e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    }
   ],
   "source": [
    "# Train VGG16 model\n",
    "# history_vgg = model_vgg.fit(train_generator_vgg,\n",
    "#                              steps_per_epoch=100,\n",
    "#                              epochs=30)\n",
    "\n",
    "# Train Xception model\n",
    "history_xception = model_xception.fit(train_generator,\n",
    "                                       steps_per_epoch=100,\n",
    "                                       epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c880f17-807d-47ed-9cb1-27eb9f43cf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Xception model\n",
    "val_loss_xception, val_accuracy_xception = model_xception.evaluate(validation_generator)\n",
    "print(f'Xception Validation Loss: {val_loss_xception}, Validation Accuracy: {val_accuracy_xception}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c10c4be-3058-408b-9dd6-11b832e1b101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86e334f-5da5-4c61-9f1d-d5c94736f1e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf84bd8-0afa-4a3a-bfbf-60e6c800325f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a79dc4c-e8e7-4af4-b07b-0eed43973aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8775612d-33f3-41ce-87ce-43d49fbcc1ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
